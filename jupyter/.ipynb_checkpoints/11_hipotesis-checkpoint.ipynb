{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hipótesis\n",
    "\n",
    "Tenemos:\n",
    "\n",
    "1) Hay privilegio para los grupos de conectar con SC\n",
    "2) Éste privilegio está sesgado en favor de los hombres\n",
    "\n",
    "Tenemos tres hipótesis\n",
    " 1) Las mujeres se salen de la carrera\n",
    " \n",
    " 2) Hay una diferencia de conexión local a SC entre hombres y mujeres\n",
    " \n",
    " 3) Hay otro sesgo de género presente que no tiene que ver con estructurada de redes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hipotesis 2\n",
    "\n",
    "Hay una diferencia en la conectividad local entre los que están conectados con SC:\n",
    "\n",
    "1. Los exitosos 5 años después tienen más conexiones\n",
    "2. Los exitosos 5 años después tienen más colaboraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation table\n",
    "\n",
    "We take cites from 1990 to 2019 avoiding self-cites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cite = pd.read_csv(\"../data/processed/cites.csv\")\n",
    "\n",
    "cite = cite[(cite.t_year >= 1990) & (cite.t_year < 2020)]\n",
    "cite = cite[(cite.s_year >= 1990) & (cite.s_year < 2020)]\n",
    "\n",
    "cite = cite[cite.target != cite.source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = pd.read_csv(\"../data/processed/adjacency_papers.csv\")\n",
    "\n",
    "papers = papers[(papers.t_year >= 1990) & (papers.t_year < 2020)]\n",
    "papers = papers[(papers.s_year >= 1990) & (papers.s_year < 2020)]\n",
    "\n",
    "papers = papers[papers.target != papers.source]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors table\n",
    "\n",
    "There are two author tables: \n",
    "\n",
    "1. One with the comparable groups A and B (`people`) and \n",
    "2. the one with the all the authors found in the RePEc repository (`all_people`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = pd.read_csv(\"../data/processed/network_people.csv\")\n",
    "all_people = pd.read_csv(\"../data/processed/people.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Places table\n",
    "\n",
    "We use the institution to infer the place of work of the authors. We have:\n",
    "\n",
    "1. The region (continent)\n",
    "2. The sub-region (sub-continent)\n",
    "3. Country 3-letter code\n",
    "4. The institution's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = pd.read_csv(\"../data/processed/institution.csv\")\n",
    "\n",
    "places = places[['Handle', 'Primary-Name', 'alpha-3', 'region', 'sub-region']].set_index(\"Handle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding place of work to people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_people = pd.merge(all_people,\n",
    "                  places,\n",
    "                  left_on=\"Workplace-Institution\",\n",
    "                  right_index=True,\n",
    "                  how=\"left\")\n",
    "\n",
    "# all_people = all_people[all_people.region.notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding gender to the citation table\n",
    "\n",
    "We have two genders for each cite:\n",
    "\n",
    "1. Gender of the source (`gender_s`)\n",
    "3. Gender of the target (`gender`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cite = pd.merge(cite,\n",
    "                all_people[[\"Short-Id\", \"gender\"]],\n",
    "                how=\"left\",\n",
    "                left_on=\"target\",\n",
    "                right_on=\"Short-Id\")\n",
    "\n",
    "cite = pd.merge(cite,\n",
    "                all_people[[\"Short-Id\", \"gender\"]].rename(columns={\"gender\":\"gender_s\"}),\n",
    "                how=\"left\",\n",
    "                left_on=\"source\",\n",
    "                right_on=\"Short-Id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the citations without the gender of the target from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cite = cite[cite.gender.notna()]\n",
    "cite = cite[cite.gender_s.notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super-cited researchers\n",
    "\n",
    "Let's get some basic statistics of the super-cited researchers in our citation network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_cite = nx.from_pandas_edgelist(cite,\n",
    "                            source='source',\n",
    "                            target='target',\n",
    "                            create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = pd.DataFrame(G_cite.in_degree(), columns=[\"author\", \"degree\"])\n",
    "mu = degree.degree.mean()\n",
    "r = degree.degree.quantile(.75) - degree.degree.quantile(.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_cited = degree[degree.degree >= mu + 1.5 * r].author.unique()\n",
    "cite_sc = cite[cite.target.isin(super_cited)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaboration network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pd.read_csv(\"../data/processed/co_author.csv\")\n",
    "\n",
    "col = col[(col.year >= 1990) & (col.year < 2020)]\n",
    "\n",
    "col = col.drop_duplicates(subset=['author1', 'author2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add gender to collaboration network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pd.merge(col,\n",
    "               all_people[['Short-Id', 'gender']],\n",
    "               left_on='author1',\n",
    "               right_on='Short-Id',\n",
    "               how='left')\n",
    "col = pd.merge(col,\n",
    "               all_people[['Short-Id', 'gender']],\n",
    "               left_on='author2',\n",
    "               right_on='Short-Id',\n",
    "               suffixes=[\"_1\", \"_2\"],\n",
    "               how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.dropna(subset=['gender_1', 'gender_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super cited by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "super_cited = []\n",
    "for year in [2000, 2003] + list(range(2005, 2020)):\n",
    "    years.append(year)\n",
    "    if year == 2000:\n",
    "        chunk = cite[cite.s_year <= year]\n",
    "    elif year == 2003:\n",
    "        chunk = cite[(cite.s_year > 2000) & (cite.s_year <= 2003)]\n",
    "    elif year == 2005:\n",
    "        chunk = cite[(cite.s_year > 2003) & (cite.s_year <= 2005)]\n",
    "    else:\n",
    "        chunk = cite[cite.s_year == year]\n",
    "    G_year = nx.from_pandas_edgelist(chunk,\n",
    "                                     source=\"source\",\n",
    "                                     target=\"target\",\n",
    "                                     create_using=nx.DiGraph)\n",
    "    degree = pd.DataFrame(G_year.in_degree(), columns=[\"author\", \"degree\"])\n",
    "    mu = degree.degree.mean()\n",
    "    r = degree.degree.quantile(.75) - degree.degree.quantile(.25)\n",
    "    scited = degree[degree.degree >= mu + 1.5 * r].author.unique()\n",
    "    super_cited.append(set(scited))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighbors by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = []\n",
    "succ_neighbors = []\n",
    "for i, year in enumerate(years[:-5]):\n",
    "    if year == 2000:\n",
    "        chunk = col[col.year <= year]\n",
    "    elif year == 2003:\n",
    "        chunk = col[(col.year > 2000) & (col.year <= 2003)]\n",
    "    elif year == 2005:\n",
    "        chunk = col[(col.year > 2003) & (col.year <= 2005)]\n",
    "    else:\n",
    "        chunk = col[col.year == year]\n",
    "    G_year = nx.from_pandas_edgelist(chunk,\n",
    "                                     source=\"author1\",\n",
    "                                     target=\"author2\",\n",
    "                                     create_using=nx.Graph)\n",
    "    n = []\n",
    "    for sc in super_cited[i]:\n",
    "        if sc in G_year:\n",
    "            n.extend(list(G_year[sc]))\n",
    "    n = set(n)\n",
    "    if i == 0:\n",
    "        n = n - super_cited[i]\n",
    "    else:\n",
    "        for j in range(0, i+1):\n",
    "            n = n - super_cited[j]\n",
    "    neighbors.append(n)\n",
    "    succ_neighbors.append(n & super_cited[i+5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_authors1(x):\n",
    "    return sorted(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_authors2(x):\n",
    "    return sorted(x)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "author1 = col[['author1', 'author2']].apply(order_authors1, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "author2 = col[['author1', 'author2']].apply(order_authors2, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "col['author1'] = author1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "col['author2'] = author2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = []\n",
    "for i, year in enumerate(years[:-5]):\n",
    "    chunk = col[col.year==year]\n",
    "    chunk = chunk.groupby(['author1', 'author2']).size().rename('weight').reset_index()\n",
    "    G = nx.from_pandas_edgelist(chunk,\n",
    "                                source='author1',\n",
    "                                target='author2',\n",
    "                                edge_attr='weight')\n",
    "    graphs.append(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4322"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphs[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural parameters\n",
    "\n",
    "Induced subgraph (node and SC neighbors)\n",
    " 1. Clustering\n",
    " 2. Degree\n",
    " 3. Weighted degree\n",
    " \n",
    "First neighbors\n",
    " 1. Nodes\n",
    " 2. Edges\n",
    " 3. Weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
