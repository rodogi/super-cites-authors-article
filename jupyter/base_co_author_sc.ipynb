{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear base con\n",
    "\n",
    "Para cada año entre 2000 y 2014:\n",
    "\n",
    "- Colaboró o no con SC\n",
    "- Fue SC o no 5 años después\n",
    "- Edad a la hora de colaborar\n",
    "- Activo 5 años después\n",
    "- Género"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation table\n",
    "\n",
    "We take cites from 1990 to 2019 avoiding self-cites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "cite = pd.read_csv(\"../data/processed/cites.csv\")\n",
    "\n",
    "cite = cite[(cite.t_year >= 1990) & (cite.t_year < 2020)]\n",
    "cite = cite[(cite.s_year >= 1990) & (cite.s_year < 2020)]\n",
    "\n",
    "cite = cite[cite.target != cite.source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = pd.read_csv(\"../data/processed/adjacency_papers.csv\")\n",
    "\n",
    "papers = papers[(papers.t_year >= 1990) & (papers.t_year < 2020)]\n",
    "papers = papers[(papers.s_year >= 1990) & (papers.s_year < 2020)]\n",
    "\n",
    "papers = papers[papers.target != papers.source]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors table\n",
    "\n",
    "There are two author tables: \n",
    "\n",
    "1. One with the comparable groups A and B (`people`) and \n",
    "2. the one with the all the authors found in the RePEc repository (`all_people`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = pd.read_csv(\"../data/processed/network_people.csv\")\n",
    "all_people = pd.read_csv(\"../data/processed/people.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Places table\n",
    "\n",
    "We use the institution to infer the place of work of the authors. We have:\n",
    "\n",
    "1. The region (continent)\n",
    "2. The sub-region (sub-continent)\n",
    "3. Country 3-letter code\n",
    "4. The institution's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = pd.read_csv(\"../data/processed/institution.csv\")\n",
    "\n",
    "places = places[['Handle', 'Primary-Name', 'alpha-3', 'region', 'sub-region']].set_index(\"Handle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding place of work to people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_people = pd.merge(all_people,\n",
    "                  places,\n",
    "                  left_on=\"Workplace-Institution\",\n",
    "                  right_index=True,\n",
    "                  how=\"left\")\n",
    "\n",
    "# all_people = all_people[all_people.region.notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding gender to the citation table\n",
    "\n",
    "We have two genders for each cite:\n",
    "\n",
    "1. Gender of the source (`gender_s`)\n",
    "3. Gender of the target (`gender`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "cite = pd.merge(cite,\n",
    "                all_people[[\"Short-Id\", \"gender\"]],\n",
    "                how=\"left\",\n",
    "                left_on=\"target\",\n",
    "                right_on=\"Short-Id\")\n",
    "\n",
    "cite = pd.merge(cite,\n",
    "                all_people[[\"Short-Id\", \"gender\"]].rename(columns={\"gender\":\"gender_s\"}),\n",
    "                how=\"left\",\n",
    "                left_on=\"source\",\n",
    "                right_on=\"Short-Id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the citations without the gender of the target from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "cite = cite[cite.gender.notna()]\n",
    "cite = cite[cite.gender_s.notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super-cited researchers\n",
    "\n",
    "Let's get some basic statistics of the super-cited researchers in our citation network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_cite = nx.from_pandas_edgelist(cite,\n",
    "                            source='source',\n",
    "                            target='target',\n",
    "                            create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = pd.DataFrame(G_cite.in_degree(), columns=[\"author\", \"degree\"])\n",
    "mu = degree.degree.mean()\n",
    "r = degree.degree.quantile(.75) - degree.degree.quantile(.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_cited = degree[degree.degree >= mu + 1.5 * r].author.unique()\n",
    "cite_sc = cite[cite.target.isin(super_cited)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaboration network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pd.read_csv(\"../data/processed/co_author_2.csv\")\n",
    "\n",
    "col = col[(col.year >= 1990) & (col.year < 2020)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add gender to collaboration network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pd.merge(col,\n",
    "               all_people[['Short-Id', 'gender']],\n",
    "               left_on='author1',\n",
    "               right_on='Short-Id',\n",
    "               how='left')\n",
    "col = pd.merge(col,\n",
    "               all_people[['Short-Id', 'gender']],\n",
    "               left_on='author2',\n",
    "               right_on='Short-Id',\n",
    "               suffixes=[\"_1\", \"_2\"],\n",
    "               how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.dropna(subset=['gender_1', 'gender_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super cited by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "super_cited = []\n",
    "for year in [2000, 2003] + list(range(2005, 2020)):\n",
    "    years.append(year)\n",
    "    if year == 2000:\n",
    "        chunk = cite[cite.s_year <= year]\n",
    "    elif year == 2003:\n",
    "        chunk = cite[(cite.s_year > 2000) & (cite.s_year <= 2003)]\n",
    "    elif year == 2005:\n",
    "        chunk = cite[(cite.s_year > 2003) & (cite.s_year <= 2005)]\n",
    "    else:\n",
    "        chunk = cite[cite.s_year == year]\n",
    "    G_year = nx.from_pandas_edgelist(chunk,\n",
    "                                     source=\"source\",\n",
    "                                     target=\"target\",\n",
    "                                     create_using=nx.DiGraph)\n",
    "    degree = pd.DataFrame(G_year.in_degree(), columns=[\"author\", \"degree\"])\n",
    "    mu = degree.degree.mean()\n",
    "    r = degree.degree.quantile(.75) - degree.degree.quantile(.25)\n",
    "    scited = degree[degree.degree >= mu + 1.5 * r].author.unique()\n",
    "    super_cited.append(set(scited))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## People not SC with a first colaboration with one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = dict(zip(all_people['Short-Id'], all_people['gender']))\n",
    "YEARS_AHEAD = 5\n",
    "\n",
    "neighbors = []\n",
    "women_neighbors = []\n",
    "succ_neighbors = []\n",
    "women_succ_neighbors = []\n",
    "not_neighbors = []\n",
    "women_not_neighbors = []\n",
    "succ_not_neighbors = []\n",
    "women_succ_not_neighbors = []\n",
    "for i, year in enumerate(years[:-YEARS_AHEAD]):\n",
    "    if year == 2000:\n",
    "        chunk = col[col.year <= year]\n",
    "    elif year == 2003:\n",
    "        chunk = col[(col.year > 2000) & (col.year <= 2003)]\n",
    "    elif year == 2005:\n",
    "        chunk = col[(col.year > 2003) & (col.year <= 2005)]\n",
    "    else:\n",
    "        chunk = col[col.year == year]\n",
    "    G_year = nx.from_pandas_edgelist(chunk,\n",
    "                                     source=\"author1\",\n",
    "                                     target=\"author2\",\n",
    "                                     create_using=nx.Graph)\n",
    "    n = []\n",
    "    for sc in super_cited[i]:\n",
    "        if sc in G_year:\n",
    "            n.extend(list(G_year[sc]))\n",
    "    n = set(n)\n",
    "    not_n = set(list(G_year)) - n\n",
    "    if i == 0:\n",
    "        n = n - super_cited[i]\n",
    "        not_n = not_n - super_cited[i]\n",
    "    else:\n",
    "        for j in range(0, i+1):\n",
    "            n = n - super_cited[j]\n",
    "            not_n = not_n - super_cited[j]\n",
    "    n_w = set([x for x in n if genders[x]=='female'])\n",
    "    not_n_w = set([x for x in not_n if genders[x]=='female'])\n",
    "    neighbors.append(n)\n",
    "    not_neighbors.append(not_n)\n",
    "    women_neighbors.append(n_w)\n",
    "    women_not_neighbors.append(not_n_w)\n",
    "    succ_neighbors.append(n & super_cited[i+YEARS_AHEAD])\n",
    "    succ_not_neighbors.append(not_n & super_cited[i+YEARS_AHEAD])\n",
    "    women_succ_neighbors.append(n_w & super_cited[i+YEARS_AHEAD])\n",
    "    women_succ_not_neighbors.append(not_n_w & super_cited[i+YEARS_AHEAD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## People active at each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = pd.read_csv('../data/econometry/base_1_todos.csv')\n",
    "\n",
    "article = article.dropna(subset=['year', 'gender'])\n",
    "\n",
    "graphs = []\n",
    "for i, year in enumerate(years):\n",
    "    if year == 2000:\n",
    "        chunk = article[article.year <= year]\n",
    "    elif year == 2003:\n",
    "        chunk = article[(article.year > 2000) & (article.year <= 2003)]\n",
    "    elif year == 2005:\n",
    "        chunk = article[(article.year > 2003) & (article.year <= 2005)]\n",
    "    else:\n",
    "        chunk = article[article.year == year]\n",
    "    graphs.append(chunk['Short-Id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age of people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Everything from 1970 onward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = article.sort_values(by='year')\n",
    "\n",
    "age = article[article.year >= 1970].groupby('Short-Id').year.first().rename('age').reset_index()\n",
    "\n",
    "all_people = pd.merge(all_people, age, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = dict(zip(all_people['Short-Id'], all_people['age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_sc = [neighbors[i] | not_neighbors[i] for i in range(len(neighbors))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "columns = ['author', 'year', 'colaborator', 'gender', 'successful', 'active', 'age']\n",
    "for i, people in enumerate(not_sc):\n",
    "    for node in people:\n",
    "        _age = years[i] - ages[node]\n",
    "        _colaborator = 0\n",
    "        _active = 0\n",
    "        _success = 0\n",
    "        _year = years[i]\n",
    "        _gender = 'male'\n",
    "        if node in neighbors[i]:\n",
    "            _colaborator = 1\n",
    "        if node in graphs[i+YEARS_AHEAD]:\n",
    "            _active = 1\n",
    "        if node in women_neighbors[i] or node in women_not_neighbors[i]:\n",
    "            _gender = 'female'\n",
    "        if node in succ_neighbors[i] or node in succ_not_neighbors[i]:\n",
    "            _success = 1\n",
    "        data.append([node, _year, _colaborator, _gender, _success, _active, _age])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "networks = []\n",
    "for i, group in enumerate(not_sc):\n",
    "    print(i)\n",
    "    if years[i] == 2000:\n",
    "        chunk = col[((col.author1.isin(group) | col.author2.isin(group))) & col.year <= year]\n",
    "    elif years[i] == 2003:\n",
    "        chunk = col[((col.author1.isin(group) | col.author2.isin(group))) & (col.year > 2000) & (col.year <= 2003)]\n",
    "    elif years[i] == 2005:\n",
    "        chunk = col[((col.author1.isin(group) | col.author2.isin(group))) & (col.year > 2003) & (col.year <= 2005)]\n",
    "    else:\n",
    "        chunk = col[((col.author1.isin(group) | col.author2.isin(group))) & (col.year==years[i])]\n",
    "    chunk = chunk.groupby(['author1', 'author2']).size().rename('weight').reset_index()\n",
    "    G_y = nx.from_pandas_edgelist(chunk, source='author1', target='author2', edge_attr='weight')\n",
    "    networks.append(G_y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "columns = ['author', 'year', 'nodes', 'edges', 'weight', 'clustering']\n",
    "for i, group in enumerate(not_sc):\n",
    "    print(i)\n",
    "    G_y = networks[i]\n",
    "    for node in group:\n",
    "        neighbors = set(G_y.neighbors(node)) & super_cited[i]\n",
    "        neighbors = list(neighbors)\n",
    "        G = G_y.subgraph(neighbors + [node])\n",
    "        c = nx.average_clustering(G)\n",
    "        order = len(G)\n",
    "        edges = len(G.edges)\n",
    "        weight = sum(dict(G.degree(weight='weight')).values())\n",
    "        data.append([node, years[i], order, edges, weight, c])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_net, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/processed/new_colabs.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
